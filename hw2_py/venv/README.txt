Homework 2: Descriptive Modeling and Unsupervised Learning of Textual Data


Files in this project:
main.py
preprocessor.py
ldapreprocessor.py
ngrams_docmatrix.py
matrix.py
kmeans.py
similarity.py
evaluation.py
visualization.py


Requirements:

This program was written in Python 3.6. It is unknown if the program will run correctly for other
versions of Python.

The following Python libraries are used

1. NLTK
2. spaCy
3. gensim
4. sklearn
5. matplotlib
6. pandas
7. numpy

$ pip install -U <name of library>

The spaCy library extension ‘en_core_web_sm’ is also used and can be installed as a package:
$ python -m spacy download en_core_web_sm

NTLK uses a model called 'wordnet'. It can be installed by entering the Python3 interpreter, importing nltk,
and installing nltk.download('wordnet'). Then exit the interpreter.
$ python3
>>> import nltk
>>> nltk.download('wordnet')


Instructions:

1. Run program by typing "python3 main.py" at the command line.
2. topics.txt (generated by the NER and sliding windows/n-grams preprocessor) and Ltopics.txt (generated
by the LDA preprocessor) will be output to the same directory as main.py.
3. A document term matrix transformed by TF-IDF will be generated and processed by the K-Means clustering
algorithm. The results are displayed visually.


More information about the libraries at:
https://www.nltk.org/install.html
https://spacy.io/usage/
https://spacy.io/usage/models
https://pypi.org/project/gensim/
https://scikit-learn.org
https://matplotlib.org
https://pandas.pydata.org
http://www.numpy.org